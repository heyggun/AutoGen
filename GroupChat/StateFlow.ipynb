{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **AutoGen > Old Blog (Archived) > StateFlow**\n",
    "https://microsoft.github.io/autogen/0.2/blog/2024/02/29/StateFlow/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## StateFlow\n",
    "\n",
    "**유한 상태 기계(Finite State Machine, FSM)**는 예를 들어 교통 신호 제어와 같은 실제 응용 프로그램을 모니터링하는 제어 시스템으로 사용된다. 정의된 **상태 기계**는 현재 상태를 기준으로 무엇을 해야 할지를 결정하는 행동 모델이다. *상태*는 **FSM**이 있을 수 있는 하나의 상화을 나타낸다. 이러한 개념을 바탕으로, 우리는 LLM의 작업 해결 과정을 모델링하는 데 FSM을 사용하고자 한다.\n",
    "\n",
    "LLM을 사용하여 여러 단계를 거쳐 해결해야 하는 작업이 주어졌을 때, 작업 해결 프로세스의 각 단계를 하나의 상태로 매핑할 수 있다.\n",
    "예를 들어 SQL 작업을 생각해 보자. (아래의 그림 참고) \n",
    "이 작업에 대한 바람직한 절차는 다음과 같아.\n",
    "\n",
    "(1) 데이터베이스 내의 테이블 및 컬럼에 대한 정보 수집\n",
    "(2) 원하는 정보를 조회하는 쿼리 구성\n",
    "(3) 작업이 해결되었는지 검증하고, 프로세스를 종료\n",
    "\n",
    "각 단계에 대해 대응하는 상태를 생성하고, 실패 상황을 처리하기 위한 **오류 상태(error state)**도 정의한다. 그림에서는 실행 결과에 따라 빨간 화살표(실패)와 초록 화살표(성공)가 *상태 전이*를 나타낸다. *상태간 전이*는 특정 규칙에 기반한다. 예를 들어 `\"Submit\"` 명령이 성공적으로 수행되면 모델은 `\"종료 상태(End state)\"`로 전이한다. \n",
    "상태에 도달하면, 정의된 출력함수(output functions)의 일련의 작업이 실행된다. 예를 들어 **`M_i -> E`**은 모델을 먼저 호출하고 그 이후 SQL 명령을 실행함을 의미한다.\n",
    "\n",
    "\n",
    "\n",
    "![](https://velog.velcdn.com/images/heyggun/post/360649ab-6fcc-437a-9377-2d03df9ba54f/image.png)\n",
    "\n",
    "\n",
    "위 그림은 **SQL Task**와 **Bash Task**에서의 에이전트 작업 흐름을 시각적으로 표현한 다이어그램이다. 각 작업에서 **LLM(Large Language Model)이 특정 instruciton을 가진 에이전트로 동작하면서 오류를 탐지하고 수정하면서 해결하는 과정이다.\n",
    " \n",
    "각 기호들은 다음과 같다.\n",
    "- **Init** : 초기 프롬프트 입력 (P->E, *Prompter* -> *Execution*)\n",
    "- **M_i** -> E : *M_i*는 특정 instrauction을 따르는 LLM, *E*는 실행환경이다. \n",
    "- **초록색 원** : 작업 수행 단계 (정상 플로우)\n",
    "- **빨간색 원** : 오류 처리 단계 (Error)\n",
    "- **화살표** : 단계 간 전이\n",
    "- **Exit** : 작업 제출 및 종료 \n",
    "\n",
    "\n",
    "**[SQL Task]**\n",
    "\n",
    "SQL Task의 전체 흐름은 *Init* 단계에서 시작해서 *Observe(M_1->E)*로 데이터를 관찰한다. *Select (M_2->E)* 로 쿼리를 선택하고 *Verify(M_3->E)* 선택한 쿼리를 검증한다. 그 후에 *End*로 제출하면 성공적인 종료이다.\n",
    "\n",
    "이 때, 중간에 오류가 발생하면 오류 처리 플로우로 빠지는데 *Obseve*,*Select*, *Verify* 단계에서 **Error(M_4->E)**로 전환될 수 있다. Error는 자체 루프를 돌며 재시도가 가능하고, Error에서 *Select*나 *Verify*로 복귀할 수 있다.\n",
    "\n",
    "해당 로직에서 *Select* <-> *Verify* 에서 **Select**, **Desc** 키워드를 기반으로 상호 피드백을 진행한다.\n",
    "\n",
    "**[Bash Task]**\n",
    "\n",
    "Bash Task의 전체흐름은 *Init*에서 시작해서 *Solve(M_1->E)* 에서 문제 해결을 시도한다. 그리고 *Verify(M_2->E)*로 실행 결과를 확인한 후에 *End*로 제출하면 성공적인 종료이다.\n",
    "\n",
    "이 때, 중간에 오류가 발생하면 *Solve*, *Verify* 단계에서 **Error(M_3->E)**로 전환한다. Error는 역시 루프로 반복 가능하다. 오류 발생 시 다시 *Verity*로 돌아가거나, 처음부터 다시 *Sovle*로 돌아갈 수 있다. \n",
    "\n",
    "위의 로직들의 핵심 차이점은 **SQL task**는 주요단계가 `Observe->Select->Verify` 이고, **Bash Task**는 주요단계가 `Solve -> Verify` 이다. **SQL task**는 검증-선택의 반복 단계에서 `SELECT/DESC`로 상호 피드백을 진행하고 **Bash Task**는 단방향 흐름 중심이다. \n",
    "\n",
    "이 다이어그램은 **에이전트 기반 문제 해결** 프로세스에서 `다단계 피드백 루프`, `오류 처리 로직`, `역할 분리된 모델` 사용 전략을 보여주고 있다. 특히 **SQL 문제 해결**은 **탐색-선택-검증**의 명확한 단계화를 통해 구조적 문제를 해결을 강조하고, Bash는 **실행 중심**의 간단한 흐름으로 실용적인 접근을 보여준다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments\n",
    "\n",
    "\n",
    "**InterCode** : 여기서는 InterCode 벤치마크의 SQL 작업과 Bash 작업에서 StateFlow를 평가하며, GPT-3.5-Turbo와 GPT-4-Turbo 모두를 사용했다. 포괄적인 비교를 위해 다양한 지표를 기록했다.\n",
    "**`'SR(성공률)'`**은 성능을 측정하고, **`'Truns(턴수)'`**는 환경과의 상호작용 횟수를 나타내며, **`'Error Rate(오류율)'`**는 실행된 명령어 중 오류가 발생한 비율을 나타낸다. 또한 LLM 사용 비용도 기록하였다.\n",
    "다음과 같은 기준 방법으로 비교를 진행하였는데, \n",
    "\n",
    "(1) **ReAct** : 모델이 생각과 행동을 생성하도록 유도하는 few-shot 프롬프트 방식\n",
    "(2) **Plan & Solve** : 먼저 모델에게 계획을 제안하게 한 다음, 이를 실행하게 하는 두 단계 프롬프트 전략\n",
    "\n",
    "Bash 작업에 대한 결과는 아래에 제시되어 있다.\n",
    "![](https://velog.velcdn.com/images/heyggun/post/0cd11ea0-f023-4bab-b1ac-60d8920db4de/image.png)\n",
    "\n",
    "\n",
    "**ALFWorld** : 여기서는 **TextWorld** 환경에서 구현된 텍스트 기반의 합성 게임인 `ALFWorld 벤치마크`에서도 실험을 수행했다. `GPT-3.5-Turbo`를 사용했으며, 평균 3회의 시도에서 결과를 측정했다. 다음의 방법들로 함께 평가를 진행했다.\n",
    "\n",
    "(1) **ReAct** : ReAct의 two-shot 프롬프트를 사용하였으며, 각 작업 유형에 따라 별도의 프롬프트를 사용한다.\n",
    "(2) **ALFChat (2 에이전트)**: AutoGen의 설정을 따른 두 개의 에이전트 시스템으로, 보조 에이전트와 실행 에이전트로 구성된다. ALFChat은 ReAct를 기반으로 하며, 프롬프트를 대화 형식으로 수정한 방식이다.\n",
    "(3) **ALFChat (3 에이전트)** : 2-에이전트 시스템을 기반으로 하여, 보조 에이전트가 동일한 행동을 세 번 연속 출력할 경우 상식 정보를 제공하는 grounding 에이전트를 추가한 방식이다.\n",
    "\n",
    "두 작업 모두에서 **StateFlow**는 가장 높은 성능과 가장 낮은 비용을 달성했다. 자세한 내용은 본 논문을 참고 !\n",
    "\n",
    "> **paper : StateFlow: Enhancing LLM Task-Solving through State-Driven Workflows**\n",
    "https://arxiv.org/abs/2403.11322"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement StateFlow With GroupChat\n",
    "\n",
    "여기서는 *GroupChat*을 사용해 **StateFlow**를 구축하는 방법을 설명한다. **`FSM Group Chat`**에서는 에이전트 간 전환을 제약할 수 있는 `transition graph)` 전이 그래프를 입력하는 새로운 GroupChat 기능을 소개했다. 이 기능은 에이전트의 설명(description) 파마미터에 상태 전이 조건을 자연어로 기술 해야 하며, LLM이 해당 설명을 받아 다음 에이전트를 결정하게 된다.\n",
    "\n",
    "> **FSM Group Chat**\n",
    "https://microsoft.github.io/autogen/0.2/blog/2024/02/11/FSM-GroupChat/\n",
    "\n",
    "\n",
    "여기서는 **GroupChat** 객체의 `speaker_selection_method`에 전달할 수 있는 **사용자 지정 발화자 선택 함수(custom speaker selection function)**을 사용한다. 이 함수는 에이전트 간의 전이 로직을 사용자 정의할 수 있게 해주며, FSM Group Chat에서 소개된 전이 그래프와 함께 사용할 수 있다. 현재 StateFlow 구현은 사용자가 전이 그래프를 **직접 덮어쓸 수 있도록**도 지원한다. 이러한 전이는 현재 발화자(speaker)와 컨텍스트 히스토리의 정적 검사(예: 마지막 메시지에 'Error'가 포함되어 있는지 확인)를 기반으로 정의될 수 있다. \n",
    "\n",
    "**GroupChat**을 사용해서 **`state-oriented workflow(상태 지향 워크플로우)`**를 구성하는 예제를 제시한다. 여기서는 `speaker_selection_method` 파라미터에 전달될 사용자 정의 발화 선택 함수를 정의한다. 이 예제의 작업은 주어진 주제와 관련된 연구 논문을 검색하고, 해당 논문들을 마크다운 테이블 형식으로 정리하는 것이다.\n",
    "\n",
    "![](https://velog.velcdn.com/images/heyggun/post/b9145a1e-3ae6-4661-a9b7-007798d1d1b7/image.png)\n",
    "\n",
    "위는 코드를 생성하고 실행해서 추가 연구를 통해 작업을 완성하는 일련의 프로세스를 설명하는 다이어그램이다. \n",
    "\n",
    "*Init* 프로세스를 시작하는 초기화 단계에서 시작해서 *Retrieve(**C->E**)* 코드를 작성(Coder)하고 코드를 실행한다(Coe Executor). *Research(**R**) *성공적으로 결과를 얻으면 추가적인 리서치를 진행한다. 연구가 끝나면 *End*(**Exit**) 작업을 종료한다.\n",
    "위 로직에서 Coder가 코드를 작성하고 Code Executor라 이를 실행해서 실행에 성공하면 *Research* 단계로, 오류 발생시 *Retrieve* 단계로 다시 돌아가서 재 시도한다. (Error 루프)\n",
    "\n",
    "---\n",
    "여기서는 다음과 같은 에이전트를 정의했다.\n",
    "\n",
    "- **Initializer** : 작업을 전달하여 워크플로우를 시작한다.\n",
    "- **Coder**: 코드를 작성하여 인터넷에서 논문을 검색한다.\n",
    "- **Executor** : 코드를 실행한다.\n",
    "- **Scientist** : 논문을 읽고 요약을 작성한다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autogen\n",
    "from config import settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = settings.openai_api_key.get_secret_value()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_config = {\n",
    "    \"config_list\":\n",
    "        [\n",
    "            {\n",
    "                \"model\" : \"gpt-4o-mini\",\n",
    "                \"api_key\" : api_key\n",
    "            }\n",
    "        ]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "initializer = autogen.UserProxyAgent(\n",
    "    name=\"init\",\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "\n",
    "coder = autogen.AssistantAgent(\n",
    "    name=\"Coder\",\n",
    "    system_message=\"\"\"You are the Coder. Write Python Code to retrieve papers from arxiv.\"\"\",\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "\n",
    "executor = autogen.UserProxyAgent(\n",
    "    name=\"Executor\",\n",
    "    system_message=\"\"\"Executor. Execute the code written by the Coder and report the result.\"\"\",\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "\n",
    "scientist = autogen.AssistantAgent(\n",
    "    name=\"Scientist\",\n",
    "    system_message = \"\"\"You are the Scientist. Please categorize papers after seeing their abstracts printed and create a markdown table with Domain, Title, Authors, Summary and Link.\n",
    "Return 'TERMINATE' in the end.\"\"\",\n",
    "llm_config=llm_config,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Initializer** : 작업을 전달하여 워크플로우를 시작한다.\n",
    "- **Coder**: 코드를 작성하여 인터넷에서 논문을 검색한다.\n",
    "- **Executor** : 코드를 실행한다.\n",
    "- **Scientist** : 논문을 읽고 요약을 작성한다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def state_transition(last_speaker, groupchat):\n",
    "    messages = groupchat.messages\n",
    "    \n",
    "    if last_speaker is initializer:\n",
    "        return coder\n",
    "    elif last_speaker is coder:\n",
    "        return executor\n",
    "    elif last_speaker is executor:\n",
    "        if messages[-1][\"content\"] == \"exitcode: 1\":\n",
    "            return coder\n",
    "        else:\n",
    "            return scientist\n",
    "    elif last_speaker == \"Scientist\":\n",
    "        return None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupchat = autogen.GroupChat(\n",
    "    agents=[initializer, coder, executor, scientist],\n",
    "    messages=[],\n",
    "    max_round=20,\n",
    "    speaker_selection_method=state_transition,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33minit\u001b[0m (to chat_manager):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: Coder\n",
      "\u001b[0m\n",
      "\u001b[33mCoder\u001b[0m (to chat_manager):\n",
      "\n",
      "To retrieve papers from arXiv, you can use the `arxiv` API, which allows you to search for and fetch papers in a variety of formats. Below is a simple example of how to use the `arxiv` Python package to retrieve papers. Make sure to install the package first if you haven't done so:\n",
      "\n",
      "```bash\n",
      "pip install arxiv\n",
      "```\n",
      "\n",
      "Here's a sample code snippet to search for papers on arXiv:\n",
      "\n",
      "```python\n",
      "import arxiv\n",
      "\n",
      "def search_arxiv(query, max_results=5):\n",
      "    # Create a search object with the specified query and max results\n",
      "    search = arxiv.Search(\n",
      "        query=query,\n",
      "        max_results=max_results,\n",
      "        sort_by=arxiv.SortCriterion.Relevance\n",
      "    )\n",
      "    \n",
      "    # Iterate through the search results and print paper details\n",
      "    for result in search.results():\n",
      "        print(f'Title: {result.title}')\n",
      "        print(f'Authors: {\", \".join([author.name for author in result.authors])}')\n",
      "        print(f'Summary: {result.summary}')\n",
      "        print(f'Published: {result.published}')\n",
      "        print(f'PDF Link: {result.pdf_url}')\n",
      "        print('---')\n",
      "\n",
      "# Example usage\n",
      "search_query = \"machine learning\"\n",
      "search_arxiv(search_query)\n",
      "```\n",
      "\n",
      "### Explanation:\n",
      "1. **Import the `arxiv` package**: This allows you to access the arXiv API.\n",
      "2. **Define a function `search_arxiv()`**: This function takes a query string and an optional maximum number of results to return.\n",
      "3. **Create a search object**: Using the `arxiv.Search` constructor, initialize the search parameters.\n",
      "4. **Iterate through the results**: For each result, print the title, authors, summary, publication date, and PDF link.\n",
      "5. **Call the function with a search query**: The example usage searches for papers related to \"machine learning\".\n",
      "\n",
      "You can customize the search query as needed, and modify the `max_results` parameter to control how many papers you retrieve.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: Executor\n",
      "\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> NO HUMAN INPUT RECEIVED.\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> EXECUTING CODE BLOCK 0 (inferred language is bash)...\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> EXECUTING CODE BLOCK 1 (inferred language is python)...\u001b[0m\n",
      "\u001b[33mExecutor\u001b[0m (to chat_manager):\n",
      "\n",
      "exitcode: 0 (execution succeeded)\n",
      "Code output: \n",
      "Collecting arxiv\n",
      "  Downloading arxiv-2.2.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting feedparser~=6.0.10 (from arxiv)\n",
      "  Downloading feedparser-6.0.11-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting requests~=2.32.0 (from arxiv)\n",
      "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting sgmllib3k (from feedparser~=6.0.10->arxiv)\n",
      "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting charset-normalizer<4,>=2 (from requests~=2.32.0->arxiv)\n",
      "  Downloading charset_normalizer-3.4.1-cp313-cp313-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (35 kB)\n",
      "Collecting idna<4,>=2.5 (from requests~=2.32.0->arxiv)\n",
      "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests~=2.32.0->arxiv)\n",
      "  Downloading urllib3-2.4.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests~=2.32.0->arxiv)\n",
      "  Downloading certifi-2025.4.26-py3-none-any.whl.metadata (2.5 kB)\n",
      "Downloading arxiv-2.2.0-py3-none-any.whl (11 kB)\n",
      "Downloading feedparser-6.0.11-py3-none-any.whl (81 kB)\n",
      "Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Downloading certifi-2025.4.26-py3-none-any.whl (159 kB)\n",
      "Downloading charset_normalizer-3.4.1-cp313-cp313-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (140 kB)\n",
      "Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
      "Downloading urllib3-2.4.0-py3-none-any.whl (128 kB)\n",
      "Building wheels for collected packages: sgmllib3k\n",
      "  Building wheel for sgmllib3k (pyproject.toml): started\n",
      "  Building wheel for sgmllib3k (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6089 sha256=215b88500d4ad59697ef2a7426ea42e9f85bbf2fbb4cfc5d51b04425636884be\n",
      "  Stored in directory: /root/.cache/pip/wheels/3d/4d/ef/37cdccc18d6fd7e0dd7817dcdf9146d4d6789c32a227a28134\n",
      "Successfully built sgmllib3k\n",
      "Installing collected packages: sgmllib3k, urllib3, idna, feedparser, charset-normalizer, certifi, requests, arxiv\n",
      "Successfully installed arxiv-2.2.0 certifi-2025.4.26 charset-normalizer-3.4.1 feedparser-6.0.11 idna-3.10 requests-2.32.3 sgmllib3k-1.0.0 urllib3-2.4.0\n",
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\n",
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1\n",
      "[notice] To update, run: pip install --upgrade pip\n",
      "\n",
      "/workspace/tmp_code_6ba0332eafac3c5006cb56c5a92f91cd.py:12: DeprecationWarning: The 'Search.results' method is deprecated, use 'Client.results' instead\n",
      "  for result in search.results():\n",
      "Title: Lecture Notes: Optimization for Machine Learning\n",
      "Authors: Elad Hazan\n",
      "Summary: Lecture notes on optimization for machine learning, derived from a course at\n",
      "Princeton University and tutorials given in MLSS, Buenos Aires, as well as\n",
      "Simons Foundation, Berkeley.\n",
      "Published: 2019-09-08 21:49:42+00:00\n",
      "PDF Link: http://arxiv.org/pdf/1909.03550v1\n",
      "---\n",
      "Title: An Optimal Control View of Adversarial Machine Learning\n",
      "Authors: Xiaojin Zhu\n",
      "Summary: I describe an optimal control view of adversarial machine learning, where the\n",
      "dynamical system is the machine learner, the input are adversarial actions, and\n",
      "the control costs are defined by the adversary's goals to do harm and be hard\n",
      "to detect. This view encompasses many types of adversarial machine learning,\n",
      "including test-item attacks, training-data poisoning, and adversarial reward\n",
      "shaping. The view encourages adversarial machine learning researcher to utilize\n",
      "advances in control theory and reinforcement learning.\n",
      "Published: 2018-11-11 14:28:34+00:00\n",
      "PDF Link: http://arxiv.org/pdf/1811.04422v1\n",
      "---\n",
      "Title: Minimax deviation strategies for machine learning and recognition with short learning samples\n",
      "Authors: Michail Schlesinger, Evgeniy Vodolazskiy\n",
      "Summary: The article is devoted to the problem of small learning samples in machine\n",
      "learning. The flaws of maximum likelihood learning and minimax learning are\n",
      "looked into and the concept of minimax deviation learning is introduced that is\n",
      "free of those flaws.\n",
      "Published: 2017-07-16 09:15:08+00:00\n",
      "PDF Link: http://arxiv.org/pdf/1707.04849v1\n",
      "---\n",
      "Title: Machine Learning for Clinical Predictive Analytics\n",
      "Authors: Wei-Hung Weng\n",
      "Summary: In this chapter, we provide a brief overview of applying machine learning\n",
      "techniques for clinical prediction tasks. We begin with a quick introduction to\n",
      "the concepts of machine learning and outline some of the most common machine\n",
      "learning algorithms. Next, we demonstrate how to apply the algorithms with\n",
      "appropriate toolkits to conduct machine learning experiments for clinical\n",
      "prediction tasks. The objectives of this chapter are to (1) understand the\n",
      "basics of machine learning techniques and the reasons behind why they are\n",
      "useful for solving clinical prediction problems, (2) understand the intuition\n",
      "behind some machine learning models, including regression, decision trees, and\n",
      "support vector machines, and (3) understand how to apply these models to\n",
      "clinical prediction problems using publicly available datasets via case\n",
      "studies.\n",
      "Published: 2019-09-19 22:02:00+00:00\n",
      "PDF Link: http://arxiv.org/pdf/1909.09246v1\n",
      "---\n",
      "Title: Towards Modular Machine Learning Solution Development: Benefits and Trade-offs\n",
      "Authors: Samiyuru Menik, Lakshmish Ramaswamy\n",
      "Summary: Machine learning technologies have demonstrated immense capabilities in\n",
      "various domains. They play a key role in the success of modern businesses.\n",
      "However, adoption of machine learning technologies has a lot of untouched\n",
      "potential. Cost of developing custom machine learning solutions that solve\n",
      "unique business problems is a major inhibitor to far-reaching adoption of\n",
      "machine learning technologies. We recognize that the monolithic nature\n",
      "prevalent in today's machine learning applications stands in the way of\n",
      "efficient and cost effective customized machine learning solution development.\n",
      "In this work we explore the benefits of modular machine learning solutions and\n",
      "discuss how modular machine learning solutions can overcome some of the major\n",
      "solution engineering limitations of monolithic machine learning solutions. We\n",
      "analyze the trade-offs between modular and monolithic machine learning\n",
      "solutions through three deep learning problems; one text based and the two\n",
      "image based. Our experimental results show that modular machine learning\n",
      "solutions have a promising potential to reap the solution engineering\n",
      "advantages of modularity while gaining performance and data advantages in a way\n",
      "the monolithic machine learning solutions do not permit.\n",
      "Published: 2023-01-23 22:54:34+00:00\n",
      "PDF Link: http://arxiv.org/pdf/2301.09753v1\n",
      "---\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: Scientist\n",
      "\u001b[0m\n",
      "\u001b[33mScientist\u001b[0m (to chat_manager):\n",
      "\n",
      "Here is a markdown table summarizing the identified papers based on their abstracts:\n",
      "\n",
      "```markdown\n",
      "| Domain                     | Title                                                                 | Authors                                 | Summary                                                                                                                                                                                                                                                                              | Link                                   |\n",
      "|---------------------------|-----------------------------------------------------------------------|-----------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|----------------------------------------|\n",
      "| Machine Learning           | Lecture Notes: Optimization for Machine Learning                     | Elad Hazan                             | Lecture notes on optimization for machine learning, derived from a course at Princeton University and tutorials given in MLSS, Buenos Aires, as well as Simons Foundation, Berkeley.                                                                                            | [PDF Link](http://arxiv.org/pdf/1909.03550v1) |\n",
      "| Adversarial Machine Learning| An Optimal Control View of Adversarial Machine Learning              | Xiaojin Zhu                            | An optimal control view of adversarial machine learning, encompassing many types of adversarial machine learning, including test-item attacks, training-data poisoning, and adversarial reward shaping, encouraging researchers to utilize advances in control theory and reinforcement learning. | [PDF Link](http://arxiv.org/pdf/1811.04422v1) |\n",
      "| Machine Learning           | Minimax deviation strategies for machine learning and recognition with short learning samples      | Michail Schlesinger, Evgeniy Vodolazskiy | This article addresses the problem of small learning samples in machine learning, introducing the concept of minimax deviation learning that is free of flaws inherent in maximum likelihood and minimax learning.                                                                 | [PDF Link](http://arxiv.org/pdf/1707.04849v1) |\n",
      "| Clinical Predictive Analytics| Machine Learning for Clinical Predictive Analytics                   | Wei-Hung Weng                          | Overview of applying machine learning techniques for clinical prediction, discussing common algorithms and demonstrating their application through case studies to understand their usefulness and intuition for clinical prediction problems.                                         | [PDF Link](http://arxiv.org/pdf/1909.09246v1) |\n",
      "| Modular Machine Learning    | Towards Modular Machine Learning Solution Development: Benefits and Trade-offs | Samiyuru Menik, Lakshmish Ramaswamy   | Discusses the potential of modular machine learning solutions to overcome limitations of monolithic applications, analyzing trade-offs through experiments on deep learning problems and showing promise in solution engineering advantages.                                              | [PDF Link](http://arxiv.org/pdf/2301.09753v1) |\n",
      "```\n",
      "\n",
      "TERMINATE\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> TERMINATING RUN (110ac18e-3cd4-4bd1-bd91-c68458e17ade): No next speaker selected\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChatResult(chat_id=None, chat_history=[{'content': '', 'role': 'assistant', 'name': 'init'}, {'content': 'To retrieve papers from arXiv, you can use the `arxiv` API, which allows you to search for and fetch papers in a variety of formats. Below is a simple example of how to use the `arxiv` Python package to retrieve papers. Make sure to install the package first if you haven\\'t done so:\\n\\n```bash\\npip install arxiv\\n```\\n\\nHere\\'s a sample code snippet to search for papers on arXiv:\\n\\n```python\\nimport arxiv\\n\\ndef search_arxiv(query, max_results=5):\\n    # Create a search object with the specified query and max results\\n    search = arxiv.Search(\\n        query=query,\\n        max_results=max_results,\\n        sort_by=arxiv.SortCriterion.Relevance\\n    )\\n    \\n    # Iterate through the search results and print paper details\\n    for result in search.results():\\n        print(f\\'Title: {result.title}\\')\\n        print(f\\'Authors: {\", \".join([author.name for author in result.authors])}\\')\\n        print(f\\'Summary: {result.summary}\\')\\n        print(f\\'Published: {result.published}\\')\\n        print(f\\'PDF Link: {result.pdf_url}\\')\\n        print(\\'---\\')\\n\\n# Example usage\\nsearch_query = \"machine learning\"\\nsearch_arxiv(search_query)\\n```\\n\\n### Explanation:\\n1. **Import the `arxiv` package**: This allows you to access the arXiv API.\\n2. **Define a function `search_arxiv()`**: This function takes a query string and an optional maximum number of results to return.\\n3. **Create a search object**: Using the `arxiv.Search` constructor, initialize the search parameters.\\n4. **Iterate through the results**: For each result, print the title, authors, summary, publication date, and PDF link.\\n5. **Call the function with a search query**: The example usage searches for papers related to \"machine learning\".\\n\\nYou can customize the search query as needed, and modify the `max_results` parameter to control how many papers you retrieve.', 'name': 'Coder', 'role': 'user'}, {'content': \"exitcode: 0 (execution succeeded)\\nCode output: \\nCollecting arxiv\\n  Downloading arxiv-2.2.0-py3-none-any.whl.metadata (6.3 kB)\\nCollecting feedparser~=6.0.10 (from arxiv)\\n  Downloading feedparser-6.0.11-py3-none-any.whl.metadata (2.4 kB)\\nCollecting requests~=2.32.0 (from arxiv)\\n  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\\nCollecting sgmllib3k (from feedparser~=6.0.10->arxiv)\\n  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\\n  Installing build dependencies: started\\n  Installing build dependencies: finished with status 'done'\\n  Getting requirements to build wheel: started\\n  Getting requirements to build wheel: finished with status 'done'\\n  Preparing metadata (pyproject.toml): started\\n  Preparing metadata (pyproject.toml): finished with status 'done'\\nCollecting charset-normalizer<4,>=2 (from requests~=2.32.0->arxiv)\\n  Downloading charset_normalizer-3.4.1-cp313-cp313-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (35 kB)\\nCollecting idna<4,>=2.5 (from requests~=2.32.0->arxiv)\\n  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\\nCollecting urllib3<3,>=1.21.1 (from requests~=2.32.0->arxiv)\\n  Downloading urllib3-2.4.0-py3-none-any.whl.metadata (6.5 kB)\\nCollecting certifi>=2017.4.17 (from requests~=2.32.0->arxiv)\\n  Downloading certifi-2025.4.26-py3-none-any.whl.metadata (2.5 kB)\\nDownloading arxiv-2.2.0-py3-none-any.whl (11 kB)\\nDownloading feedparser-6.0.11-py3-none-any.whl (81 kB)\\nDownloading requests-2.32.3-py3-none-any.whl (64 kB)\\nDownloading certifi-2025.4.26-py3-none-any.whl (159 kB)\\nDownloading charset_normalizer-3.4.1-cp313-cp313-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (140 kB)\\nDownloading idna-3.10-py3-none-any.whl (70 kB)\\nDownloading urllib3-2.4.0-py3-none-any.whl (128 kB)\\nBuilding wheels for collected packages: sgmllib3k\\n  Building wheel for sgmllib3k (pyproject.toml): started\\n  Building wheel for sgmllib3k (pyproject.toml): finished with status 'done'\\n  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6089 sha256=215b88500d4ad59697ef2a7426ea42e9f85bbf2fbb4cfc5d51b04425636884be\\n  Stored in directory: /root/.cache/pip/wheels/3d/4d/ef/37cdccc18d6fd7e0dd7817dcdf9146d4d6789c32a227a28134\\nSuccessfully built sgmllib3k\\nInstalling collected packages: sgmllib3k, urllib3, idna, feedparser, charset-normalizer, certifi, requests, arxiv\\nSuccessfully installed arxiv-2.2.0 certifi-2025.4.26 charset-normalizer-3.4.1 feedparser-6.0.11 idna-3.10 requests-2.32.3 sgmllib3k-1.0.0 urllib3-2.4.0\\nWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\\n\\n[notice] A new release of pip is available: 25.0.1 -> 25.1\\n[notice] To update, run: pip install --upgrade pip\\n\\n/workspace/tmp_code_6ba0332eafac3c5006cb56c5a92f91cd.py:12: DeprecationWarning: The 'Search.results' method is deprecated, use 'Client.results' instead\\n  for result in search.results():\\nTitle: Lecture Notes: Optimization for Machine Learning\\nAuthors: Elad Hazan\\nSummary: Lecture notes on optimization for machine learning, derived from a course at\\nPrinceton University and tutorials given in MLSS, Buenos Aires, as well as\\nSimons Foundation, Berkeley.\\nPublished: 2019-09-08 21:49:42+00:00\\nPDF Link: http://arxiv.org/pdf/1909.03550v1\\n---\\nTitle: An Optimal Control View of Adversarial Machine Learning\\nAuthors: Xiaojin Zhu\\nSummary: I describe an optimal control view of adversarial machine learning, where the\\ndynamical system is the machine learner, the input are adversarial actions, and\\nthe control costs are defined by the adversary's goals to do harm and be hard\\nto detect. This view encompasses many types of adversarial machine learning,\\nincluding test-item attacks, training-data poisoning, and adversarial reward\\nshaping. The view encourages adversarial machine learning researcher to utilize\\nadvances in control theory and reinforcement learning.\\nPublished: 2018-11-11 14:28:34+00:00\\nPDF Link: http://arxiv.org/pdf/1811.04422v1\\n---\\nTitle: Minimax deviation strategies for machine learning and recognition with short learning samples\\nAuthors: Michail Schlesinger, Evgeniy Vodolazskiy\\nSummary: The article is devoted to the problem of small learning samples in machine\\nlearning. The flaws of maximum likelihood learning and minimax learning are\\nlooked into and the concept of minimax deviation learning is introduced that is\\nfree of those flaws.\\nPublished: 2017-07-16 09:15:08+00:00\\nPDF Link: http://arxiv.org/pdf/1707.04849v1\\n---\\nTitle: Machine Learning for Clinical Predictive Analytics\\nAuthors: Wei-Hung Weng\\nSummary: In this chapter, we provide a brief overview of applying machine learning\\ntechniques for clinical prediction tasks. We begin with a quick introduction to\\nthe concepts of machine learning and outline some of the most common machine\\nlearning algorithms. Next, we demonstrate how to apply the algorithms with\\nappropriate toolkits to conduct machine learning experiments for clinical\\nprediction tasks. The objectives of this chapter are to (1) understand the\\nbasics of machine learning techniques and the reasons behind why they are\\nuseful for solving clinical prediction problems, (2) understand the intuition\\nbehind some machine learning models, including regression, decision trees, and\\nsupport vector machines, and (3) understand how to apply these models to\\nclinical prediction problems using publicly available datasets via case\\nstudies.\\nPublished: 2019-09-19 22:02:00+00:00\\nPDF Link: http://arxiv.org/pdf/1909.09246v1\\n---\\nTitle: Towards Modular Machine Learning Solution Development: Benefits and Trade-offs\\nAuthors: Samiyuru Menik, Lakshmish Ramaswamy\\nSummary: Machine learning technologies have demonstrated immense capabilities in\\nvarious domains. They play a key role in the success of modern businesses.\\nHowever, adoption of machine learning technologies has a lot of untouched\\npotential. Cost of developing custom machine learning solutions that solve\\nunique business problems is a major inhibitor to far-reaching adoption of\\nmachine learning technologies. We recognize that the monolithic nature\\nprevalent in today's machine learning applications stands in the way of\\nefficient and cost effective customized machine learning solution development.\\nIn this work we explore the benefits of modular machine learning solutions and\\ndiscuss how modular machine learning solutions can overcome some of the major\\nsolution engineering limitations of monolithic machine learning solutions. We\\nanalyze the trade-offs between modular and monolithic machine learning\\nsolutions through three deep learning problems; one text based and the two\\nimage based. Our experimental results show that modular machine learning\\nsolutions have a promising potential to reap the solution engineering\\nadvantages of modularity while gaining performance and data advantages in a way\\nthe monolithic machine learning solutions do not permit.\\nPublished: 2023-01-23 22:54:34+00:00\\nPDF Link: http://arxiv.org/pdf/2301.09753v1\\n---\\n\", 'name': 'Executor', 'role': 'user'}, {'content': 'Here is a markdown table summarizing the identified papers based on their abstracts:\\n\\n```markdown\\n| Domain                     | Title                                                                 | Authors                                 | Summary                                                                                                                                                                                                                                                                              | Link                                   |\\n|---------------------------|-----------------------------------------------------------------------|-----------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|----------------------------------------|\\n| Machine Learning           | Lecture Notes: Optimization for Machine Learning                     | Elad Hazan                             | Lecture notes on optimization for machine learning, derived from a course at Princeton University and tutorials given in MLSS, Buenos Aires, as well as Simons Foundation, Berkeley.                                                                                            | [PDF Link](http://arxiv.org/pdf/1909.03550v1) |\\n| Adversarial Machine Learning| An Optimal Control View of Adversarial Machine Learning              | Xiaojin Zhu                            | An optimal control view of adversarial machine learning, encompassing many types of adversarial machine learning, including test-item attacks, training-data poisoning, and adversarial reward shaping, encouraging researchers to utilize advances in control theory and reinforcement learning. | [PDF Link](http://arxiv.org/pdf/1811.04422v1) |\\n| Machine Learning           | Minimax deviation strategies for machine learning and recognition with short learning samples      | Michail Schlesinger, Evgeniy Vodolazskiy | This article addresses the problem of small learning samples in machine learning, introducing the concept of minimax deviation learning that is free of flaws inherent in maximum likelihood and minimax learning.                                                                 | [PDF Link](http://arxiv.org/pdf/1707.04849v1) |\\n| Clinical Predictive Analytics| Machine Learning for Clinical Predictive Analytics                   | Wei-Hung Weng                          | Overview of applying machine learning techniques for clinical prediction, discussing common algorithms and demonstrating their application through case studies to understand their usefulness and intuition for clinical prediction problems.                                         | [PDF Link](http://arxiv.org/pdf/1909.09246v1) |\\n| Modular Machine Learning    | Towards Modular Machine Learning Solution Development: Benefits and Trade-offs | Samiyuru Menik, Lakshmish Ramaswamy   | Discusses the potential of modular machine learning solutions to overcome limitations of monolithic applications, analyzing trade-offs through experiments on deep learning problems and showing promise in solution engineering advantages.                                              | [PDF Link](http://arxiv.org/pdf/2301.09753v1) |\\n```\\n\\nTERMINATE', 'name': 'Scientist', 'role': 'user'}], summary='Here is a markdown table summarizing the identified papers based on their abstracts:\\n\\n```markdown\\n| Domain                     | Title                                                                 | Authors                                 | Summary                                                                                                                                                                                                                                                                              | Link                                   |\\n|---------------------------|-----------------------------------------------------------------------|-----------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|----------------------------------------|\\n| Machine Learning           | Lecture Notes: Optimization for Machine Learning                     | Elad Hazan                             | Lecture notes on optimization for machine learning, derived from a course at Princeton University and tutorials given in MLSS, Buenos Aires, as well as Simons Foundation, Berkeley.                                                                                            | [PDF Link](http://arxiv.org/pdf/1909.03550v1) |\\n| Adversarial Machine Learning| An Optimal Control View of Adversarial Machine Learning              | Xiaojin Zhu                            | An optimal control view of adversarial machine learning, encompassing many types of adversarial machine learning, including test-item attacks, training-data poisoning, and adversarial reward shaping, encouraging researchers to utilize advances in control theory and reinforcement learning. | [PDF Link](http://arxiv.org/pdf/1811.04422v1) |\\n| Machine Learning           | Minimax deviation strategies for machine learning and recognition with short learning samples      | Michail Schlesinger, Evgeniy Vodolazskiy | This article addresses the problem of small learning samples in machine learning, introducing the concept of minimax deviation learning that is free of flaws inherent in maximum likelihood and minimax learning.                                                                 | [PDF Link](http://arxiv.org/pdf/1707.04849v1) |\\n| Clinical Predictive Analytics| Machine Learning for Clinical Predictive Analytics                   | Wei-Hung Weng                          | Overview of applying machine learning techniques for clinical prediction, discussing common algorithms and demonstrating their application through case studies to understand their usefulness and intuition for clinical prediction problems.                                         | [PDF Link](http://arxiv.org/pdf/1909.09246v1) |\\n| Modular Machine Learning    | Towards Modular Machine Learning Solution Development: Benefits and Trade-offs | Samiyuru Menik, Lakshmish Ramaswamy   | Discusses the potential of modular machine learning solutions to overcome limitations of monolithic applications, analyzing trade-offs through experiments on deep learning problems and showing promise in solution engineering advantages.                                              | [PDF Link](http://arxiv.org/pdf/2301.09753v1) |\\n```\\n\\n', cost={'usage_including_cached_inference': {'total_cost': 0}, 'usage_excluding_cached_inference': {'total_cost': 0}}, human_input=[''])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manager = autogen.GroupChatManager(groupchat=groupchat)\n",
    "\n",
    "initializer.initiate_chat(manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: \n",
      "user: To retrieve papers from arXiv, you can use the `arxiv` API, which allows you to search for and fetch papers in a variety of formats. Below is a simple example of how to use the `arxiv` Python package to retrieve papers. Make sure to install the package first if you haven't done so:\n",
      "\n",
      "```bash\n",
      "pip install arxiv\n",
      "```\n",
      "\n",
      "Here's a sample code snippet to search for papers on arXiv:\n",
      "\n",
      "```python\n",
      "import arxiv\n",
      "\n",
      "def search_arxiv(query, max_results=5):\n",
      "    # Create a search object with the specified query and max results\n",
      "    search = arxiv.Search(\n",
      "        query=query,\n",
      "        max_results=max_results,\n",
      "        sort_by=arxiv.SortCriterion.Relevance\n",
      "    )\n",
      "    \n",
      "    # Iterate through the search results and print paper details\n",
      "    for result in search.results():\n",
      "        print(f'Title: {result.title}')\n",
      "        print(f'Authors: {\", \".join([author.name for author in result.authors])}')\n",
      "        print(f'Summary: {result.summary}')\n",
      "        print(f'Published: {result.published}')\n",
      "        print(f'PDF Link: {result.pdf_url}')\n",
      "        print('---')\n",
      "\n",
      "# Example usage\n",
      "search_query = \"machine learning\"\n",
      "search_arxiv(search_query)\n",
      "```\n",
      "\n",
      "### Explanation:\n",
      "1. **Import the `arxiv` package**: This allows you to access the arXiv API.\n",
      "2. **Define a function `search_arxiv()`**: This function takes a query string and an optional maximum number of results to return.\n",
      "3. **Create a search object**: Using the `arxiv.Search` constructor, initialize the search parameters.\n",
      "4. **Iterate through the results**: For each result, print the title, authors, summary, publication date, and PDF link.\n",
      "5. **Call the function with a search query**: The example usage searches for papers related to \"machine learning\".\n",
      "\n",
      "You can customize the search query as needed, and modify the `max_results` parameter to control how many papers you retrieve.\n",
      "user: exitcode: 0 (execution succeeded)\n",
      "Code output: \n",
      "Collecting arxiv\n",
      "  Downloading arxiv-2.2.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting feedparser~=6.0.10 (from arxiv)\n",
      "  Downloading feedparser-6.0.11-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting requests~=2.32.0 (from arxiv)\n",
      "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting sgmllib3k (from feedparser~=6.0.10->arxiv)\n",
      "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting charset-normalizer<4,>=2 (from requests~=2.32.0->arxiv)\n",
      "  Downloading charset_normalizer-3.4.1-cp313-cp313-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (35 kB)\n",
      "Collecting idna<4,>=2.5 (from requests~=2.32.0->arxiv)\n",
      "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests~=2.32.0->arxiv)\n",
      "  Downloading urllib3-2.4.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests~=2.32.0->arxiv)\n",
      "  Downloading certifi-2025.4.26-py3-none-any.whl.metadata (2.5 kB)\n",
      "Downloading arxiv-2.2.0-py3-none-any.whl (11 kB)\n",
      "Downloading feedparser-6.0.11-py3-none-any.whl (81 kB)\n",
      "Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Downloading certifi-2025.4.26-py3-none-any.whl (159 kB)\n",
      "Downloading charset_normalizer-3.4.1-cp313-cp313-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (140 kB)\n",
      "Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
      "Downloading urllib3-2.4.0-py3-none-any.whl (128 kB)\n",
      "Building wheels for collected packages: sgmllib3k\n",
      "  Building wheel for sgmllib3k (pyproject.toml): started\n",
      "  Building wheel for sgmllib3k (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6089 sha256=215b88500d4ad59697ef2a7426ea42e9f85bbf2fbb4cfc5d51b04425636884be\n",
      "  Stored in directory: /root/.cache/pip/wheels/3d/4d/ef/37cdccc18d6fd7e0dd7817dcdf9146d4d6789c32a227a28134\n",
      "Successfully built sgmllib3k\n",
      "Installing collected packages: sgmllib3k, urllib3, idna, feedparser, charset-normalizer, certifi, requests, arxiv\n",
      "Successfully installed arxiv-2.2.0 certifi-2025.4.26 charset-normalizer-3.4.1 feedparser-6.0.11 idna-3.10 requests-2.32.3 sgmllib3k-1.0.0 urllib3-2.4.0\n",
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\n",
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1\n",
      "[notice] To update, run: pip install --upgrade pip\n",
      "\n",
      "/workspace/tmp_code_6ba0332eafac3c5006cb56c5a92f91cd.py:12: DeprecationWarning: The 'Search.results' method is deprecated, use 'Client.results' instead\n",
      "  for result in search.results():\n",
      "Title: Lecture Notes: Optimization for Machine Learning\n",
      "Authors: Elad Hazan\n",
      "Summary: Lecture notes on optimization for machine learning, derived from a course at\n",
      "Princeton University and tutorials given in MLSS, Buenos Aires, as well as\n",
      "Simons Foundation, Berkeley.\n",
      "Published: 2019-09-08 21:49:42+00:00\n",
      "PDF Link: http://arxiv.org/pdf/1909.03550v1\n",
      "---\n",
      "Title: An Optimal Control View of Adversarial Machine Learning\n",
      "Authors: Xiaojin Zhu\n",
      "Summary: I describe an optimal control view of adversarial machine learning, where the\n",
      "dynamical system is the machine learner, the input are adversarial actions, and\n",
      "the control costs are defined by the adversary's goals to do harm and be hard\n",
      "to detect. This view encompasses many types of adversarial machine learning,\n",
      "including test-item attacks, training-data poisoning, and adversarial reward\n",
      "shaping. The view encourages adversarial machine learning researcher to utilize\n",
      "advances in control theory and reinforcement learning.\n",
      "Published: 2018-11-11 14:28:34+00:00\n",
      "PDF Link: http://arxiv.org/pdf/1811.04422v1\n",
      "---\n",
      "Title: Minimax deviation strategies for machine learning and recognition with short learning samples\n",
      "Authors: Michail Schlesinger, Evgeniy Vodolazskiy\n",
      "Summary: The article is devoted to the problem of small learning samples in machine\n",
      "learning. The flaws of maximum likelihood learning and minimax learning are\n",
      "looked into and the concept of minimax deviation learning is introduced that is\n",
      "free of those flaws.\n",
      "Published: 2017-07-16 09:15:08+00:00\n",
      "PDF Link: http://arxiv.org/pdf/1707.04849v1\n",
      "---\n",
      "Title: Machine Learning for Clinical Predictive Analytics\n",
      "Authors: Wei-Hung Weng\n",
      "Summary: In this chapter, we provide a brief overview of applying machine learning\n",
      "techniques for clinical prediction tasks. We begin with a quick introduction to\n",
      "the concepts of machine learning and outline some of the most common machine\n",
      "learning algorithms. Next, we demonstrate how to apply the algorithms with\n",
      "appropriate toolkits to conduct machine learning experiments for clinical\n",
      "prediction tasks. The objectives of this chapter are to (1) understand the\n",
      "basics of machine learning techniques and the reasons behind why they are\n",
      "useful for solving clinical prediction problems, (2) understand the intuition\n",
      "behind some machine learning models, including regression, decision trees, and\n",
      "support vector machines, and (3) understand how to apply these models to\n",
      "clinical prediction problems using publicly available datasets via case\n",
      "studies.\n",
      "Published: 2019-09-19 22:02:00+00:00\n",
      "PDF Link: http://arxiv.org/pdf/1909.09246v1\n",
      "---\n",
      "Title: Towards Modular Machine Learning Solution Development: Benefits and Trade-offs\n",
      "Authors: Samiyuru Menik, Lakshmish Ramaswamy\n",
      "Summary: Machine learning technologies have demonstrated immense capabilities in\n",
      "various domains. They play a key role in the success of modern businesses.\n",
      "However, adoption of machine learning technologies has a lot of untouched\n",
      "potential. Cost of developing custom machine learning solutions that solve\n",
      "unique business problems is a major inhibitor to far-reaching adoption of\n",
      "machine learning technologies. We recognize that the monolithic nature\n",
      "prevalent in today's machine learning applications stands in the way of\n",
      "efficient and cost effective customized machine learning solution development.\n",
      "In this work we explore the benefits of modular machine learning solutions and\n",
      "discuss how modular machine learning solutions can overcome some of the major\n",
      "solution engineering limitations of monolithic machine learning solutions. We\n",
      "analyze the trade-offs between modular and monolithic machine learning\n",
      "solutions through three deep learning problems; one text based and the two\n",
      "image based. Our experimental results show that modular machine learning\n",
      "solutions have a promising potential to reap the solution engineering\n",
      "advantages of modularity while gaining performance and data advantages in a way\n",
      "the monolithic machine learning solutions do not permit.\n",
      "Published: 2023-01-23 22:54:34+00:00\n",
      "PDF Link: http://arxiv.org/pdf/2301.09753v1\n",
      "---\n",
      "\n",
      "user: Here is a markdown table summarizing the identified papers based on their abstracts:\n",
      "\n",
      "```markdown\n",
      "| Domain                     | Title                                                                 | Authors                                 | Summary                                                                                                                                                                                                                                                                              | Link                                   |\n",
      "|---------------------------|-----------------------------------------------------------------------|-----------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|----------------------------------------|\n",
      "| Machine Learning           | Lecture Notes: Optimization for Machine Learning                     | Elad Hazan                             | Lecture notes on optimization for machine learning, derived from a course at Princeton University and tutorials given in MLSS, Buenos Aires, as well as Simons Foundation, Berkeley.                                                                                            | [PDF Link](http://arxiv.org/pdf/1909.03550v1) |\n",
      "| Adversarial Machine Learning| An Optimal Control View of Adversarial Machine Learning              | Xiaojin Zhu                            | An optimal control view of adversarial machine learning, encompassing many types of adversarial machine learning, including test-item attacks, training-data poisoning, and adversarial reward shaping, encouraging researchers to utilize advances in control theory and reinforcement learning. | [PDF Link](http://arxiv.org/pdf/1811.04422v1) |\n",
      "| Machine Learning           | Minimax deviation strategies for machine learning and recognition with short learning samples      | Michail Schlesinger, Evgeniy Vodolazskiy | This article addresses the problem of small learning samples in machine learning, introducing the concept of minimax deviation learning that is free of flaws inherent in maximum likelihood and minimax learning.                                                                 | [PDF Link](http://arxiv.org/pdf/1707.04849v1) |\n",
      "| Clinical Predictive Analytics| Machine Learning for Clinical Predictive Analytics                   | Wei-Hung Weng                          | Overview of applying machine learning techniques for clinical prediction, discussing common algorithms and demonstrating their application through case studies to understand their usefulness and intuition for clinical prediction problems.                                         | [PDF Link](http://arxiv.org/pdf/1909.09246v1) |\n",
      "| Modular Machine Learning    | Towards Modular Machine Learning Solution Development: Benefits and Trade-offs | Samiyuru Menik, Lakshmish Ramaswamy   | Discusses the potential of modular machine learning solutions to overcome limitations of monolithic applications, analyzing trade-offs through experiments on deep learning problems and showing promise in solution engineering advantages.                                              | [PDF Link](http://arxiv.org/pdf/2301.09753v1) |\n",
      "```\n",
      "\n",
      "TERMINATE\n"
     ]
    }
   ],
   "source": [
    "for msg in manager.groupchat.messages:\n",
    "    print(f\"{msg['role']}: {msg['content']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "user-prediction-jY4gRI11-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
