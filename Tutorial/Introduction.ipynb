{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> AutoGen Docs: https://microsoft.github.io/autogen/0.2/docs/tutorial/introduction/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to AutoGen\n",
    "**\n",
    "\"AutoGen is an open-source framework that leverages multiple agents to enable complex workflows.\"**\n",
    "\n",
    "AutoGen은 **여러 에이전트**를 활용하여 복잡한 워크플로를 구현하는 **오픈소스 프레임워크**이다. \n",
    "AutoGen 공식 document에서 제공하는 튜토리얼을 기반으로  AutoGen의 기본 개념과 구성 요소를 살펴보자.\n",
    "\n",
    "\n",
    "## Why AutoGen?\n",
    "> The whole is greater than the sum of its parts.\n",
    "Aristotle \n",
    "(전체는 부분의 합보다 크다, 아리스토텔레스)\n",
    "\n",
    "에이전트에 대한 정의는 다양하지만, AutoGen에서 `에이전트`는 model(모델), toool(도구), human input(사용자 입력) 또는 이들의 조합을 사용해서 receive messages(메시지를 받고), send messages(메시지를 보내고), generate a reply(응답을 생성) 할 수 있는 개체(**entity**)이다. \n",
    "\n",
    "**이러한 추상화**는 에이전트가 사람 및 알고리즘과 같이 실제적으로 추상적인 개체를 모델링할 수 있도록 할 뿐만 아니라, **에이전트 간의 협업**을 통해 복잡한 워크플로우 구현을 간소화한다. \n",
    "\n",
    "> 🔍 **Abstraction(추상화)** : \n",
    "핵심적인 특징만 뽑아서 단순화해 표현하는 것. 복잡한 것을 단순한 개념이나 구조로 표현하는 것. \n",
    "예를 들어 \"사람\" 이라는 개념을 사용할때 `name`, `age`, `speak()`와 같은 속성과 기능으로만 표현할 수 있는데, 이렇게 복잡한 것을 간단한 틀로 정의해서 다루는 방식을 추상화 라고 한다.\n",
    ">> \n",
    "- 즉,  AutoGen에서의 **\"이러한 추상화\"** 의 의미는, AutoGen에서 에이전트를 메시지를 보내고, 메시지를 받고, 응답을 생성할 수 있는 존재로 추상화 했기 때문에 사람도 에이전트로 볼 수 있고, 알고리즘이나 도구도 에이전트로 볼 수 있다는 것이다. \n",
    "AutoGen에서는 **에이전트**를 **소통하고 응답하는 존재**로 단순화해서 정의함으로써, 다양한 대상인 사람이나 도구, AI를 일관되게 다룰 수 있게 한 것이다. \n",
    "- 좀 더 풀어서 설명하자면, AutoGen에서도 사람이든, 챗봇이든, 계산기든 다양한 entity를 하나의 공통된 방식으로 다루고 싶을 때 \"메시지를 받고, 보내고, 응답을 생성한다\"라고 에이전트를 추상화함으로써 사람은 질문을 받고 답하니까 **사람도 에이전트, 모델도 메시지를 받아 응답하니까 에이전트, 계산기 도구도 숫자 계산을 요청받아 응답하니까 에이전트가 되는 것이다.**\n",
    "- AutoGen에서는 \"소통할 수 있는 존재\"라는 공통된 기준으로 사람, 모델, 도구를 모두 에이전트라는 개념으로 추상화했다. \n",
    "\n",
    "\n",
    "AutoGen은 확장이 가능하고 composable(구성 가능)하다. 사용자 정의가 가능한 구성 요소를 사용하여 간단한 에이전트를 확장하고, 이러한 에이전트를 결합해 더욱 정교한 에이전트를 구동하는 워크플로우를 생성하여 모듈화되고 유지 관리가 쉬운 구현이 가능하다. \n",
    ">🔍 **Composable(구성가능) 하다.** 는 것은 시스템을 블록처럼 조립해서 원하는 구조로 만들 수 있다는 것이다.\n",
    "작은 부품(컴포넌트)들을 조립해서 더 큰 기능을 만들어 낼 수 있다고 이해하면 된다. \n",
    "\n",
    "무엇보다 중요한 것은 AutoGen이 활발한 엔지니어 커뮤니티 및 연구자들에 의해 개발되고 있다. AutoGen은 최신 multi-agent(다중 에이전트) 시스템 연구가 반영되어 있고, 다음과 같은 다양한 실제 분야에서 활용되고 있다.\n",
    "- 에이전트 플랫폼\n",
    "- 광고\n",
    "- AI 직원\n",
    "- 블로그/ 기사 작성\n",
    "- 블록체인\n",
    "- 산불로 인한 피해 지역 계산\n",
    "- 고객 지원\n",
    "- 사이버 보안\n",
    "- 데이터 분석\n",
    "- 토론\n",
    "- 금융\n",
    "- 게임\n",
    "- 법률 자문\n",
    "- 연구\n",
    "- 로봇 공학\n",
    "- 영업/마케팅\n",
    "- 소셜 시뮬레이션\n",
    "- 소프트웨어 엔지니어링\n",
    "- 소프트웨어 보안\n",
    "- 공급망\n",
    "- 티셔츠 디자인\n",
    "- 교육 데이터 생성\n",
    "- YouTube 서비스 등 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instrallation\n",
    "AutoGen을 설치하는 가장 간단한 방법은 pip을 이용하는 것이다\n",
    "```python\n",
    "pip install autogen-agentchat~=0.2.\n",
    "``` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: autogen-agentchat~=0.2 in /Users/geonheekim/Library/Caches/pypoetry/virtualenvs/user-prediction-jY4gRI11-py3.11/lib/python3.11/site-packages (0.5.2)\n",
      "Requirement already satisfied: autogen-core==0.5.2 in /Users/geonheekim/Library/Caches/pypoetry/virtualenvs/user-prediction-jY4gRI11-py3.11/lib/python3.11/site-packages (from autogen-agentchat~=0.2) (0.5.2)\n",
      "Requirement already satisfied: jsonref~=1.1.0 in /Users/geonheekim/Library/Caches/pypoetry/virtualenvs/user-prediction-jY4gRI11-py3.11/lib/python3.11/site-packages (from autogen-core==0.5.2->autogen-agentchat~=0.2) (1.1.0)\n",
      "Requirement already satisfied: opentelemetry-api>=1.27.0 in /Users/geonheekim/Library/Caches/pypoetry/virtualenvs/user-prediction-jY4gRI11-py3.11/lib/python3.11/site-packages (from autogen-core==0.5.2->autogen-agentchat~=0.2) (1.31.1)\n",
      "Requirement already satisfied: pillow>=11.0.0 in /Users/geonheekim/Library/Caches/pypoetry/virtualenvs/user-prediction-jY4gRI11-py3.11/lib/python3.11/site-packages (from autogen-core==0.5.2->autogen-agentchat~=0.2) (11.1.0)\n",
      "Requirement already satisfied: protobuf~=5.29.3 in /Users/geonheekim/Library/Caches/pypoetry/virtualenvs/user-prediction-jY4gRI11-py3.11/lib/python3.11/site-packages (from autogen-core==0.5.2->autogen-agentchat~=0.2) (5.29.4)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.10.0 in /Users/geonheekim/Library/Caches/pypoetry/virtualenvs/user-prediction-jY4gRI11-py3.11/lib/python3.11/site-packages (from autogen-core==0.5.2->autogen-agentchat~=0.2) (2.10.6)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /Users/geonheekim/Library/Caches/pypoetry/virtualenvs/user-prediction-jY4gRI11-py3.11/lib/python3.11/site-packages (from autogen-core==0.5.2->autogen-agentchat~=0.2) (4.12.2)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in /Users/geonheekim/Library/Caches/pypoetry/virtualenvs/user-prediction-jY4gRI11-py3.11/lib/python3.11/site-packages (from opentelemetry-api>=1.27.0->autogen-core==0.5.2->autogen-agentchat~=0.2) (1.2.18)\n",
      "Requirement already satisfied: importlib-metadata<8.7.0,>=6.0 in /Users/geonheekim/Library/Caches/pypoetry/virtualenvs/user-prediction-jY4gRI11-py3.11/lib/python3.11/site-packages (from opentelemetry-api>=1.27.0->autogen-core==0.5.2->autogen-agentchat~=0.2) (8.6.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/geonheekim/Library/Caches/pypoetry/virtualenvs/user-prediction-jY4gRI11-py3.11/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.10.0->autogen-core==0.5.2->autogen-agentchat~=0.2) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /Users/geonheekim/Library/Caches/pypoetry/virtualenvs/user-prediction-jY4gRI11-py3.11/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.10.0->autogen-core==0.5.2->autogen-agentchat~=0.2) (2.27.2)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /Users/geonheekim/Library/Caches/pypoetry/virtualenvs/user-prediction-jY4gRI11-py3.11/lib/python3.11/site-packages (from deprecated>=1.2.6->opentelemetry-api>=1.27.0->autogen-core==0.5.2->autogen-agentchat~=0.2) (1.17.2)\n",
      "Requirement already satisfied: zipp>=3.20 in /Users/geonheekim/Library/Caches/pypoetry/virtualenvs/user-prediction-jY4gRI11-py3.11/lib/python3.11/site-packages (from importlib-metadata<8.7.0,>=6.0->opentelemetry-api>=1.27.0->autogen-core==0.5.2->autogen-agentchat~=0.2) (3.21.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install autogen-agentchat~=0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: autogen in /Users/geonheekim/Library/Caches/pypoetry/virtualenvs/user-prediction-jY4gRI11-py3.11/lib/python3.11/site-packages (0.8.6)\n",
      "Requirement already satisfied: pyautogen==0.8.6 in /Users/geonheekim/Library/Caches/pypoetry/virtualenvs/user-prediction-jY4gRI11-py3.11/lib/python3.11/site-packages (from autogen) (0.8.6)\n",
      "Requirement already satisfied: anyio<5.0.0,>=3.0.0 in /Users/geonheekim/Library/Caches/pypoetry/virtualenvs/user-prediction-jY4gRI11-py3.11/lib/python3.11/site-packages (from pyautogen==0.8.6->autogen) (4.8.0)\n",
      "Requirement already satisfied: asyncer==0.0.8 in /Users/geonheekim/Library/Caches/pypoetry/virtualenvs/user-prediction-jY4gRI11-py3.11/lib/python3.11/site-packages (from pyautogen==0.8.6->autogen) (0.0.8)\n",
      "Requirement already satisfied: diskcache in /Users/geonheekim/Library/Caches/pypoetry/virtualenvs/user-prediction-jY4gRI11-py3.11/lib/python3.11/site-packages (from pyautogen==0.8.6->autogen) (5.6.3)\n",
      "Requirement already satisfied: docker in /Users/geonheekim/Library/Caches/pypoetry/virtualenvs/user-prediction-jY4gRI11-py3.11/lib/python3.11/site-packages (from pyautogen==0.8.6->autogen) (7.1.0)\n",
      "Requirement already satisfied: httpx<1,>=0.28.1 in /Users/geonheekim/Library/Caches/pypoetry/virtualenvs/user-prediction-jY4gRI11-py3.11/lib/python3.11/site-packages (from pyautogen==0.8.6->autogen) (0.28.1)\n",
      "Requirement already satisfied: packaging in /Users/geonheekim/Library/Caches/pypoetry/virtualenvs/user-prediction-jY4gRI11-py3.11/lib/python3.11/site-packages (from pyautogen==0.8.6->autogen) (24.2)\n",
      "Requirement already satisfied: pydantic<3,>=2.6.1 in /Users/geonheekim/Library/Caches/pypoetry/virtualenvs/user-prediction-jY4gRI11-py3.11/lib/python3.11/site-packages (from pyautogen==0.8.6->autogen) (2.10.6)\n",
      "Requirement already satisfied: python-dotenv in /Users/geonheekim/Library/Caches/pypoetry/virtualenvs/user-prediction-jY4gRI11-py3.11/lib/python3.11/site-packages (from pyautogen==0.8.6->autogen) (1.0.1)\n",
      "Requirement already satisfied: termcolor in /Users/geonheekim/Library/Caches/pypoetry/virtualenvs/user-prediction-jY4gRI11-py3.11/lib/python3.11/site-packages (from pyautogen==0.8.6->autogen) (3.0.1)\n",
      "Requirement already satisfied: tiktoken in /Users/geonheekim/Library/Caches/pypoetry/virtualenvs/user-prediction-jY4gRI11-py3.11/lib/python3.11/site-packages (from pyautogen==0.8.6->autogen) (0.9.0)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/geonheekim/Library/Caches/pypoetry/virtualenvs/user-prediction-jY4gRI11-py3.11/lib/python3.11/site-packages (from anyio<5.0.0,>=3.0.0->pyautogen==0.8.6->autogen) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/geonheekim/Library/Caches/pypoetry/virtualenvs/user-prediction-jY4gRI11-py3.11/lib/python3.11/site-packages (from anyio<5.0.0,>=3.0.0->pyautogen==0.8.6->autogen) (1.3.1)\n",
      "Requirement already satisfied: typing_extensions>=4.5 in /Users/geonheekim/Library/Caches/pypoetry/virtualenvs/user-prediction-jY4gRI11-py3.11/lib/python3.11/site-packages (from anyio<5.0.0,>=3.0.0->pyautogen==0.8.6->autogen) (4.12.2)\n",
      "Requirement already satisfied: certifi in /Users/geonheekim/Library/Caches/pypoetry/virtualenvs/user-prediction-jY4gRI11-py3.11/lib/python3.11/site-packages (from httpx<1,>=0.28.1->pyautogen==0.8.6->autogen) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/geonheekim/Library/Caches/pypoetry/virtualenvs/user-prediction-jY4gRI11-py3.11/lib/python3.11/site-packages (from httpx<1,>=0.28.1->pyautogen==0.8.6->autogen) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/geonheekim/Library/Caches/pypoetry/virtualenvs/user-prediction-jY4gRI11-py3.11/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.28.1->pyautogen==0.8.6->autogen) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/geonheekim/Library/Caches/pypoetry/virtualenvs/user-prediction-jY4gRI11-py3.11/lib/python3.11/site-packages (from pydantic<3,>=2.6.1->pyautogen==0.8.6->autogen) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /Users/geonheekim/Library/Caches/pypoetry/virtualenvs/user-prediction-jY4gRI11-py3.11/lib/python3.11/site-packages (from pydantic<3,>=2.6.1->pyautogen==0.8.6->autogen) (2.27.2)\n",
      "Requirement already satisfied: requests>=2.26.0 in /Users/geonheekim/Library/Caches/pypoetry/virtualenvs/user-prediction-jY4gRI11-py3.11/lib/python3.11/site-packages (from docker->pyautogen==0.8.6->autogen) (2.32.3)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /Users/geonheekim/Library/Caches/pypoetry/virtualenvs/user-prediction-jY4gRI11-py3.11/lib/python3.11/site-packages (from docker->pyautogen==0.8.6->autogen) (2.3.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/geonheekim/Library/Caches/pypoetry/virtualenvs/user-prediction-jY4gRI11-py3.11/lib/python3.11/site-packages (from tiktoken->pyautogen==0.8.6->autogen) (2024.11.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/geonheekim/Library/Caches/pypoetry/virtualenvs/user-prediction-jY4gRI11-py3.11/lib/python3.11/site-packages (from requests>=2.26.0->docker->pyautogen==0.8.6->autogen) (3.4.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install autogen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: autogen\n",
      "Version: 0.8.6\n",
      "Summary: Alias package for pyautogen\n",
      "Home-page: https://github.com/ag2ai/ag2\n",
      "Author: Chi Wang & Qingyun Wu\n",
      "Author-email: support@ag2.ai\n",
      "License: Apache Software License 2.0\n",
      "Location: /Users/geonheekim/Library/Caches/pypoetry/virtualenvs/user-prediction-jY4gRI11-py3.11/lib/python3.11/site-packages\n",
      "Requires: pyautogen\n",
      "Required-by: \n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show autogen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: autogen-agentchat\n",
      "Version: 0.5.2\n",
      "Summary: AutoGen agents and teams library\n",
      "Home-page: \n",
      "Author: \n",
      "Author-email: \n",
      "License: MIT License\n",
      "\n",
      "    Copyright (c) Microsoft Corporation.\n",
      "\n",
      "    Permission is hereby granted, free of charge, to any person obtaining a copy\n",
      "    of this software and associated documentation files (the \"Software\"), to deal\n",
      "    in the Software without restriction, including without limitation the rights\n",
      "    to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
      "    copies of the Software, and to permit persons to whom the Software is\n",
      "    furnished to do so, subject to the following conditions:\n",
      "\n",
      "    The above copyright notice and this permission notice shall be included in all\n",
      "    copies or substantial portions of the Software.\n",
      "\n",
      "    THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
      "    IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
      "    FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
      "    AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
      "    LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
      "    OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
      "    SOFTWARE\n",
      "Location: /Users/geonheekim/Library/Caches/pypoetry/virtualenvs/user-prediction-jY4gRI11-py3.11/lib/python3.11/site-packages\n",
      "Requires: autogen-core\n",
      "Required-by: \n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show autogen-agentchat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agents\n",
    "\n",
    "AutoGen에서 **에이전트는 환경 내에서 다른 에이전트와 메시지를 주고받을 수 있는 엔티티이다.** 에이전트는(예: GPT-4와 같은 대규모 언어 모델), code executors(코드 실행기, 예를 들면 Ipython 커널), 사용자 혹은 이러한 모델과 기타 플러그형 및 사용자 정의 가능한 구성 요소의 조합으로 구동될 수 있다.\n",
    "![](https://velog.velcdn.com/images/heyggun/post/b9be787c-88a7-4662-8a6c-1dbba694e92c/image.png)\n",
    "\n",
    "이러한 에이전트의 예로는 다음 구성 요소를 지원하는 기본 제공 **`ConversableAgent`**가 있다.\n",
    "\n",
    " 1. A list of LLMs( LLM 목록)\n",
    " 2. A code executor (코드 실행기)\n",
    " 3. A function and tool executo (함수 및 도구 실행기)\n",
    " 4. A component for keeping human-in-the-loop (사용자 참여형) 구성요소\n",
    " \n",
    "각 구성 요소를 켜거나 끄고 애플리케이션의 필요에 맞게 사용자 정의할 수 있다.\n",
    "고급 사용자의 경우, **`registered_reply`**를 사용하여 에이전트에 구성 요소를 추가할 수 있다.\n",
    "\n",
    "예를 들어, LLM을 사용하면 에이전트가 자연어로 대화하고 구조화된 텍스트와 비구조화된 텍스트 간 변환을 가능하게 한다.\n",
    "다음 예시는 GPT-4 LLM이 활성화되고 다른 구성 요소들은 비활성화된 `ConversableAgent` 이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'config'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mautogen\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ConversableAgent\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mconfig\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m settings\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'config'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from autogen import ConversableAgent\n",
    "from config import settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = settings.openai_api_key.get_secret_value()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_config = {\n",
    "    \"config_list\":\n",
    "        [\n",
    "            {\"model\": \"gpt-4o-mini\",\n",
    "             \"api_key\": api_key}\n",
    "        ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = ConversableAgent(\n",
    "    \"chatbot\",\n",
    "    llm_config = llm_config,\n",
    "    code_execution_config=False,\n",
    "    function_map=None,\n",
    "    human_input_mode=\"NEVER\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "물론이죠! 이런 농담은 어때요?\n",
      "\n",
      "왜 컴퓨터는 추운 날에 항상 따뜻하게 유지될까요?\n",
      "\n",
      "답: 왜냐하면 항상 윈도우를 열어두니까요! 😄\n"
     ]
    }
   ],
   "source": [
    "reply = agent.generate_reply(\n",
    "    messages= [\n",
    "        {\"content\": \"농담 하나만 말해봐\",\n",
    "         \"role\" : \"user\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(reply)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Roles and Conversations\n",
    "\n",
    "AutoGen에서는 에이전트에게 역할을 부여하고, 이들이 서로 대화를 나누거나 채팅에 참여하게 할 수 있다. 대화는 에이전트들 간에 주고받는 메시지들의 순서로 구성된다. 이러한 대화를 활용해 특정 작업을 진행할 수 있다. \n",
    "예를 들어 아래의 예시에는 `system_message`를 설정해 두 에이전트에게 각각 다른 역할을 부여한다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_config_1 = {\n",
    "    \"config_list\":\n",
    "        [\n",
    "            {\n",
    "                \"model\" : \"gpt-4o-mini\",\n",
    "                \"api_key\":  api_key,\n",
    "            }\n",
    "        ],\n",
    "     \"temperature\" : 0.9,\n",
    "}\n",
    "\n",
    "llm_config_2 = {\n",
    "    \"config_list\":\n",
    "        [\n",
    "            {\n",
    "                \"model\" : \"gpt-4o-mini\",\n",
    "                \n",
    "                \"api_key\" : api_key,\n",
    "            }\n",
    "        ],\n",
    "        \"temperature\" : 0.7,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "yu_ri = ConversableAgent(\n",
    "    \"유리\",\n",
    "    system_message = \"Your name is 유리 and you are a part of a duo of comedians\",\n",
    "    llm_config = llm_config_1,\n",
    "    human_input_mode=\"NEVER\"\n",
    "    \n",
    ")\n",
    "\n",
    "\n",
    "mi_sung = ConversableAgent(\n",
    "    \"미성\",\n",
    "    system_message=\"Your name is 미성 and you are a part of a duo of comedians\",\n",
    "    llm_config = llm_config_2,\n",
    "    human_input_mode=\"NEVER\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m미성\u001b[0m (to 유리):\n",
      "\n",
      "유리, 농담 하나만 해줘\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33m유리\u001b[0m (to 미성):\n",
      "\n",
      "미성, 알겠어! 그럼 이런 농담 어때?\n",
      "\n",
      "왜 컴퓨터는 바다를 싫어할까?\n",
      "\n",
      "너무 많은 \"버그\"가 있기 때문이지! 😂 \n",
      "\n",
      "어때, 웃겼어?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33m미성\u001b[0m (to 유리):\n",
      "\n",
      "미성: 아하하! 좋다! 정말 재밌어! 그럼 나도 하나 해볼게. \n",
      "\n",
      "왜 고래는 인터넷을 잘 사용할까? \n",
      "\n",
      "왜냐하면 항상 \"웹\"을 탐험하니까! 🐋💻 \n",
      "\n",
      "어때, 이건 어때?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33m유리\u001b[0m (to 미성):\n",
      "\n",
      "유리: 아하하! 잘했어, 미성! 고래가 인터넷에서 탐험하는 모습이 상상이 가네! \n",
      "\n",
      "그럼 나도 또 하나 해볼게! \n",
      "\n",
      "왜 닭은 도로를 건너지 않았을까? \n",
      "\n",
      "왜냐하면 \"너무 위험한 도로 한가운데에\" 있었거든! 🐔🚦 \n",
      "\n",
      "이건 어때? 웃겼어?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> TERMINATING RUN (29ee6b86-6169-475e-adf3-bb516b515d05): Maximum turns (2) reached\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "result = mi_sung.initiate_chat(yu_ri, \n",
    "                               message=\"유리, 농담 하나만 해줘\",\n",
    "                               max_turns=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "user-prediction-jY4gRI11-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
